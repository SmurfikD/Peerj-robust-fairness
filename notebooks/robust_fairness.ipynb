{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1c0bff-e0ad-4674-b565-e160d3940078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# Robustness & Fairness\n",
    "# Baseline / Typos / Noise / Drift / Bias-Mitigation\n",
    "# Dependencies: numpy, pandas, scikit-learn, matplotlib\n",
    "# ============================\n",
    "\n",
    "import os, random, string, math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, roc_auc_score,\n",
    "    roc_curve\n",
    ")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ----------------------------\n",
    "# 1) Утилиты\n",
    "# ----------------------------\n",
    "\n",
    "def set_seed(seed: int):\n",
    "    random.seed(seed); np.random.seed(seed)\n",
    "\n",
    "def make_synthetic_dataset(n=5000, n_num=10, p_group=0.5, group_bias=0.6, seed=42):\n",
    "    \"\"\"\n",
    "    Генерируем табличный датасет:\n",
    "    - numeric features: X_num ~ N(0,1)\n",
    "    - categorical feature 'state' из {A..F}\n",
    "    - protected attribute 'group' in {0,1}\n",
    "    - y зависит от линейной комбинации + смещение по группе (group_bias)\n",
    "    \"\"\"\n",
    "    set_seed(seed)\n",
    "    # числовые признаки\n",
    "    X_num = np.random.randn(n, n_num)\n",
    "    # категориальный признак \"state\"\n",
    "    states = np.array(list(\"ABCDEF\"))\n",
    "    state = np.random.choice(states, size=n, replace=True)\n",
    "    # защищённый признак\n",
    "    group = (np.random.rand(n) < p_group).astype(int)\n",
    "\n",
    "    # генерим веса и логит\n",
    "    w = np.random.randn(n_num)\n",
    "    lin = X_num @ w\n",
    "    # добавим слабую зависимость от категории (state)\n",
    "    state_effect = {s: np.random.uniform(-0.5, 0.5) for s in states}\n",
    "    lin += np.vectorize(lambda s: state_effect[s])(state)\n",
    "\n",
    "    # добавим смещение по группе (создаём потенциальный биас)\n",
    "    lin += (group * group_bias)\n",
    "\n",
    "    # вероятность класса 1\n",
    "    prob = 1 / (1 + np.exp(-lin))\n",
    "    y = (np.random.rand(n) < prob).astype(int)\n",
    "\n",
    "    df = pd.DataFrame(X_num, columns=[f\"f{i}\" for i in range(n_num)])\n",
    "    df[\"state\"] = state\n",
    "    df[\"group\"] = group\n",
    "    df[\"y\"] = y\n",
    "    return df\n",
    "\n",
    "def inject_typos(series, typo_rate=0.05, seed=0):\n",
    "    \"\"\"Вносит опечатки в строковые значения: заменяет один символ в части значений.\"\"\"\n",
    "    set_seed(seed)\n",
    "    def corrupt(s):\n",
    "        if s is None or len(s) == 0: return s\n",
    "        idx = np.random.randint(0, len(s))\n",
    "        letters = string.ascii_uppercase\n",
    "        new_char = random.choice(letters.replace(s[idx], \"\")) if s[idx] in letters else random.choice(letters)\n",
    "        return s[:idx] + new_char + s[idx+1:]\n",
    "    mask = np.random.rand(len(series)) < typo_rate\n",
    "    out = series.astype(str).copy()\n",
    "    out[mask] = out[mask].apply(corrupt)\n",
    "    return out\n",
    "\n",
    "def add_numeric_noise(X, sigma=0.5, seed=0):\n",
    "    set_seed(seed)\n",
    "    return X + np.random.normal(0, sigma, size=X.shape)\n",
    "\n",
    "def demographic_parity_gap(y_pred, group):\n",
    "    \"\"\"|P(yhat=1|A=1) - P(yhat=1|A=0)|\"\"\"\n",
    "    g1 = y_pred[group==1].mean() if (group==1).any() else 0.0\n",
    "    g0 = y_pred[group==0].mean() if (group==0).any() else 0.0\n",
    "    return float(abs(g1 - g0))\n",
    "\n",
    "def tpr(y_true, y_pred):\n",
    "    tp = ((y_true==1) & (y_pred==1)).sum()\n",
    "    p  = (y_true==1).sum()\n",
    "    return 0.0 if p==0 else tp / p\n",
    "\n",
    "def equal_opportunity_gap(y_true, y_pred, group):\n",
    "    \"\"\"|TPR(A=1) - TPR(A=0)|\"\"\"\n",
    "    tpr1 = tpr(y_true[group==1], y_pred[group==1]) if (group==1).any() else 0.0\n",
    "    tpr0 = tpr(y_true[group==0], y_pred[group==0]) if (group==0).any() else 0.0\n",
    "    return float(abs(tpr1 - tpr0))\n",
    "\n",
    "def metrics_all(y_true, y_pred, y_prob, group):\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(y_true, y_pred),\n",
    "        \"macro_precision\": precision_score(y_true, y_pred, average=\"macro\", zero_division=0),\n",
    "        \"macro_recall\": recall_score(y_true, y_pred, average=\"macro\", zero_division=0),\n",
    "        \"macro_f1\": f1_score(y_true, y_pred, average=\"macro\", zero_division=0),\n",
    "        \"roc_auc\": roc_auc_score(y_true, y_prob) if len(np.unique(y_true))==2 else np.nan,\n",
    "        \"DPG\": demographic_parity_gap(y_pred, group),\n",
    "        \"EOG\": equal_opportunity_gap(y_true, y_pred, group)\n",
    "    }\n",
    "\n",
    "def group_threshold_postprocessing(y_prob, y_true, group, grid=np.linspace(0.2, 0.8, 31)):\n",
    "    \"\"\"\n",
    "    Простая bias-mitigation: подбираем два порога (для group=0 и group=1),\n",
    "    минимизируя EOG; при равенстве — максимизируем accuracy.\n",
    "    \"\"\"\n",
    "    best = None\n",
    "    for t0 in grid:\n",
    "        for t1 in grid:\n",
    "            thr = np.where(group==1, t1, t0)\n",
    "            y_hat = (y_prob >= thr).astype(int)\n",
    "            eog = equal_opportunity_gap(y_true, y_hat, group)\n",
    "            acc = accuracy_score(y_true, y_hat)\n",
    "            score = ( -eog, acc )  # меньше EOG, больше accuracy\n",
    "            if (best is None) or (score > best[0]):\n",
    "                best = (score, (t0, t1), y_hat)\n",
    "    (_, _), (t0, t1), y_hat = best\n",
    "    return (t0, t1), y_hat\n",
    "\n",
    "# ----------------------------\n",
    "# 2) Конфиг эксперимента\n",
    "# ----------------------------\n",
    "\n",
    "N_RUNS = 5\n",
    "TEST_SIZE = 0.3\n",
    "SEED_BASE = 123\n",
    "\n",
    "os.makedirs(\"figures\", exist_ok=True)\n",
    "\n",
    "# Колонки\n",
    "NUM_COLS = [f\"f{i}\" for i in range(10)]\n",
    "CAT_COLS = [\"state\"]\n",
    "ALL_INPUT = NUM_COLS + CAT_COLS\n",
    "\n",
    "# пайплайн препроцессинга + модель\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(), NUM_COLS),\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), CAT_COLS),\n",
    "    ]\n",
    ")\n",
    "model = LogisticRegression(max_iter=2000)\n",
    "pipe = Pipeline(steps=[(\"prep\", preprocess), (\"clf\", model)])\n",
    "\n",
    "# ----------------------------\n",
    "# 3) Основной цикл\n",
    "# ----------------------------\n",
    "\n",
    "records = []\n",
    "\n",
    "for run in range(N_RUNS):\n",
    "    seed = SEED_BASE + run\n",
    "    df = make_synthetic_dataset(\n",
    "        n=5000, n_num=10, p_group=0.5, group_bias=0.6, seed=seed\n",
    "    )\n",
    "\n",
    "    X = df[ALL_INPUT + [\"group\"]].copy()  # group не кодируем, но храним отдельно\n",
    "    y = df[\"y\"].values\n",
    "    g = df[\"group\"].values\n",
    "\n",
    "    # train/test split (стратифицируем по y)\n",
    "    X_train, X_test, y_train, y_test, g_train, g_test = train_test_split(\n",
    "        X[ALL_INPUT], y, g, test_size=TEST_SIZE, stratify=y, random_state=seed\n",
    "    )\n",
    "\n",
    "    # ---- Baseline ----\n",
    "    pipe.fit(X_train, y_train)\n",
    "    prob_base = pipe.predict_proba(X_test)[:,1]\n",
    "    pred_base = (prob_base >= 0.5).astype(int)\n",
    "    m_base = metrics_all(y_test, pred_base, prob_base, g_test)\n",
    "    records.append({\"run\": run, \"scenario\": \"Baseline\", **m_base})\n",
    "\n",
    "    # ---- Typos (опечатки в категориальном) ----\n",
    "    X_test_typos = X_test.copy()\n",
    "    X_test_typos[\"state\"] = inject_typos(X_test_typos[\"state\"], typo_rate=0.05, seed=seed)\n",
    "    prob_typos = pipe.predict_proba(X_test_typos)[:,1]\n",
    "    pred_typos = (prob_typos >= 0.5).astype(int)\n",
    "    m_typos = metrics_all(y_test, pred_typos, prob_typos, g_test)\n",
    "    records.append({\"run\": run, \"scenario\": \"Typos\", **m_typos})\n",
    "\n",
    "    # ---- Noise (шум в числовых) ----\n",
    "    X_test_noise = X_test.copy()\n",
    "    X_test_noise[NUM_COLS] = add_numeric_noise(X_test_noise[NUM_COLS].values, sigma=0.5, seed=seed)\n",
    "    prob_noise = pipe.predict_proba(X_test_noise)[:,1]\n",
    "    pred_noise = (prob_noise >= 0.5).astype(int)\n",
    "    m_noise = metrics_all(y_test, pred_noise, prob_noise, g_test)\n",
    "    records.append({\"run\": run, \"scenario\": \"Noise\", **m_noise})\n",
    "\n",
    "    # ---- Drift (10% заменяем другими наблюдениями с перекошенной группой) ----\n",
    "    # формируем \"дрейфовую\" подвыборку: больше объектов группы 1\n",
    "    df_drift = make_synthetic_dataset(n=1000, n_num=10, p_group=0.8, group_bias=0.6, seed=seed+777)\n",
    "    X_drift = df_drift[ALL_INPUT]\n",
    "    y_drift = df_drift[\"y\"].values\n",
    "    g_drift = df_drift[\"group\"].values\n",
    "\n",
    "    X_test_drift = X_test.copy()\n",
    "    y_test_drift = y_test.copy()\n",
    "    g_test_drift = g_test.copy()\n",
    "\n",
    "    k = max(1, int(0.10 * len(X_test_drift)))\n",
    "    idx_replace = np.random.choice(len(X_test_drift), size=k, replace=False)\n",
    "    idx_take = np.random.choice(len(X_drift), size=k, replace=False)\n",
    "\n",
    "    X_test_drift.iloc[idx_replace] = X_drift.iloc[idx_take].values\n",
    "    y_test_drift[idx_replace] = y_drift[idx_take]\n",
    "    g_test_drift[idx_replace] = g_drift[idx_take]\n",
    "\n",
    "    prob_drift = pipe.predict_proba(X_test_drift)[:,1]\n",
    "    pred_drift = (prob_drift >= 0.5).astype(int)\n",
    "    m_drift = metrics_all(y_test_drift, pred_drift, prob_drift, g_test_drift)\n",
    "    records.append({\"run\": run, \"scenario\": \"Drift\", **m_drift})\n",
    "\n",
    "    # ---- Bias-Mitigation (подбор порогов по группам для снижения EOG) ----\n",
    "    (t0, t1), pred_mitig = group_threshold_postprocessing(prob_base, y_test, g_test)\n",
    "    m_mitig = metrics_all(y_test, pred_mitig, prob_base, g_test)  # y_prob тот же; пороги иные\n",
    "    records.append({\"run\": run, \"scenario\": \"Bias-Mitigation\", **m_mitig})\n",
    "\n",
    "# ----------------------------\n",
    "# 4) Сохранение результатов\n",
    "# ----------------------------\n",
    "\n",
    "df_runs = pd.DataFrame.from_records(records)\n",
    "df_runs.to_csv(\"per_run_results.csv\", index=False)\n",
    "\n",
    "df_mean = (\n",
    "    df_runs.groupby(\"scenario\")\n",
    "    .agg({\n",
    "        \"accuracy\":\"mean\",\"macro_precision\":\"mean\",\"macro_recall\":\"mean\",\n",
    "        \"macro_f1\":\"mean\",\"roc_auc\":\"mean\",\"DPG\":\"mean\",\"EOG\":\"mean\"\n",
    "    })\n",
    "    .reset_index()\n",
    ")\n",
    "df_mean.to_csv(\"mean_results.csv\", index=False)\n",
    "\n",
    "# Совместим для «metrics_summary.csv» как в пакете\n",
    "df_mean.round(3).to_csv(\"metrics_summary.csv\", index=False)\n",
    "\n",
    "print(\"Saved: per_run_results.csv, mean_results.csv, metrics_summary.csv\")\n",
    "\n",
    "# ----------------------------\n",
    "# 5) Графики\n",
    "# ----------------------------\n",
    "\n",
    "# Accuracy bar\n",
    "plt.figure(figsize=(7,4))\n",
    "plt.bar(df_mean[\"scenario\"], df_mean[\"accuracy\"])\n",
    "plt.title(\"Accuracy by scenario\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xticks(rotation=20)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"figures/accuracy_bar.png\", dpi=150)\n",
    "plt.close()\n",
    "\n",
    "# Robustness (как линия по Accuracy)\n",
    "plt.figure(figsize=(7,4))\n",
    "order = [\"Baseline\",\"Typos\",\"Noise\",\"Drift\",\"Bias-Mitigation\"]\n",
    "acc_vals = [df_mean.set_index(\"scenario\").loc[s,\"accuracy\"] for s in order]\n",
    "plt.plot(order, acc_vals, marker=\"o\")\n",
    "plt.title(\"Robustness (Accuracy across scenarios)\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xticks(rotation=20)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"figures/robustness_plot.png\", dpi=150)\n",
    "plt.close()\n",
    "\n",
    "# Fairness plot: DPG и EOG\n",
    "plt.figure(figsize=(7,4))\n",
    "dpg_vals = [df_mean.set_index(\"scenario\").loc[s,\"DPG\"] for s in order]\n",
    "eog_vals = [df_mean.set_index(\"scenario\").loc[s,\"EOG\"] for s in order]\n",
    "plt.plot(order, dpg_vals, marker=\"o\", label=\"DPG\")\n",
    "plt.plot(order, eog_vals, marker=\"o\", label=\"EOG\")\n",
    "plt.title(\"Fairness gaps (DPG, EOG)\")\n",
    "plt.ylabel(\"Gap\")\n",
    "plt.xticks(rotation=20)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"figures/fairness_plot.png\", dpi=150)\n",
    "plt.close()\n",
    "\n",
    "# ROC для baseline\n",
    "# Берем последний прогон (run=N_RUNS-1), baseline\n",
    "last_run = df_runs[df_runs[\"run\"]==N_RUNS-1]\n",
    "# Чтобы получить prob для ROC, пересчитаем на последнем ране (быстро)\n",
    "seed = SEED_BASE + (N_RUNS-1)\n",
    "df = make_synthetic_dataset(n=5000, n_num=10, p_group=0.5, group_bias=0.6, seed=seed)\n",
    "X = df[ALL_INPUT]; y = df[\"y\"].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=TEST_SIZE, stratify=y, random_state=seed\n",
    ")\n",
    "pipe.fit(X_train, y_train)\n",
    "prob_base = pipe.predict_proba(X_test)[:,1]\n",
    "fpr, tpr_vals, _ = roc_curve(y_test, prob_base)\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.plot(fpr, tpr_vals, label=f\"ROC (AUC={roc_auc_score(y_test, prob_base):.3f})\")\n",
    "plt.plot([0,1],[0,1], linestyle=\"--\")\n",
    "plt.xlabel(\"FPR\")\n",
    "plt.ylabel(\"TPR\")\n",
    "plt.title(\"ROC curve (Baseline)\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"figures/roc_curve.png\", dpi=150)\n",
    "plt.close()\n",
    "\n",
    "print(\"Saved figures: figures/accuracy_bar.png, figures/robustness_plot.png, figures/fairness_plot.png, figures/roc_curve.png\")\n",
    "\n",
    "# ----------------------------\n",
    "# 6) LaTeX-таблица\n",
    "# ----------------------------\n",
    "\n",
    "def to_latex_table(df):\n",
    "    cols_order = [\"scenario\",\"accuracy\",\"macro_precision\",\"macro_recall\",\"macro_f1\",\"roc_auc\",\"DPG\",\"EOG\"]\n",
    "    df2 = df[cols_order].copy()\n",
    "    df2.columns = [\"Scenario\",\"Accuracy\",\"Macro P\",\"Macro R\",\"Macro F1\",\"ROC-AUC\",\"DPG↓\",\"EOG↓\"]\n",
    "    return df2.round(3).to_latex(index=False, escape=False, caption=\"Mean metrics across scenarios\", label=\"tab:metrics\")\n",
    "\n",
    "latex = to_latex_table(df_mean)\n",
    "with open(\"table.tex\",\"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(latex)\n",
    "\n",
    "print(\"Saved LaTeX table: table.tex\")\n",
    "\n",
    "# ----------------------------\n",
    "# 7) Короткий вывод чисел на экран\n",
    "# ----------------------------\n",
    "\n",
    "print(\"\\n=== Mean results ===\")\n",
    "display(df_mean.round(3))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env: env]",
   "language": "python",
   "name": "conda-env-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
